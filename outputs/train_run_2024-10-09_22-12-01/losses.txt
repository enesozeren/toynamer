Epoch	Train Loss	Validation Loss
0	3.0473722962950616	2.781473256854339
1	2.6501003307285576	2.5593654027094863
2	2.511601162987483	2.4780519886294514
3	2.4543640074010495	2.4372831242642414
4	2.424017187159211	2.414478549528345
5	2.406268947867955	2.4005490536787457
6	2.394892144355006	2.3911576794322493
7	2.3868831779504167	2.3842461160881583
8	2.3807882848276143	2.378816599441166
9	2.3758796974286898	2.374351787787817
10	2.3717662941630855	2.3705641254407737
11	2.3682252226774847	2.3672878494104577
12	2.3651237433033963	2.364424525640535
13	2.362378711337716	2.3619072148668776
14	2.3599316947145947	2.3596827459530294
15	2.3577355373994635	2.3577008963638204
16	2.355747973898032	2.3559134896595557
17	2.353930092328612	2.3542758288388197
18	2.3522464406025505	2.3527481537577404
19	2.3506667660638096	2.3512977475114303
20	2.3491660052297165	2.3498985135109627
21	2.3477248769791763	2.3485311190294413
22	2.3463290233906124	2.347182206534208
23	2.3449686305041153	2.3458438267003365
24	2.3436372036937043	2.3445127515378057
25	2.342330088794589	2.3431888043012745
26	2.3410443086898405	2.3418733553330218
27	2.3397759562552687	2.340567166769059
28	2.3385201293288023	2.3392709656982094
29	2.337271601026974	2.3379865178887917
30	2.3360261717733217	2.3367172942979573
31	2.3347820138331317	2.3354697628963086
32	2.333541218355627	2.3342560624461393
33	2.3323165536715322	2.3330938846740596
34	2.331130289650443	2.3319981362250193
35	2.330002656429118	2.3309767729211077
36	2.328943890230742	2.3300317433553577
37	2.3279563584481364	2.3291608155598578
38	2.3270374223501085	2.328359152250244
39	2.326182355588547	2.3276203509010402
